{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91dcba38-22d9-465f-8ad1-3b14641ef75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from mycelya_torch import RemoteMachine  # use remote GPUs on demand in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25bba0a-ad9c-4206-ae61-57d6d9bbc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def train_epoch(model: nn.Module, data: list, optimizer: torch.optim.Optimizer, criterion: nn.Module, device: torch.device) -> float:\n",
    "    model.train()\n",
    "    running_loss = torch.tensor(0.0, device=device)\n",
    "    total_count = 0\n",
    "    \n",
    "    for images, labels in data:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.detach() * images.size(0)\n",
    "        total_count += images.size(0)\n",
    "        \n",
    "    return running_loss.item() / total_count\n",
    "\n",
    "def evaluate(model: nn.Module, data: list, device: torch.device) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    correct = torch.tensor(0.0, device=device)\n",
    "    total_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            correct += predictions.eq(labels).sum()\n",
    "            total_count += images.size(0)\n",
    "\n",
    "    accuracy = correct.item() / total_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285d1d70-cb76-450f-84e3-ba4f1a814654",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51352e2-82d7-4def-ba95-d4d9bed2b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spin up remote T4 machine\n",
    "machine = RemoteMachine(\"modal\", \"T4\")\n",
    "\n",
    "data_device = machine.device(\"cpu\")\n",
    "model_device = machine.device(\"cuda\")\n",
    "\n",
    "# Upload data to remote CPU\n",
    "train_data = [(images.to(data_device), labels.to(data_device)) for images, labels in train_loader]\n",
    "test_data = [(images.to(data_device), labels.to(data_device)) for images, labels in test_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd307192-25a9-4759-9f95-644ef947240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to remote GPU\n",
    "model = SimpleCNN().to(model_device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725b3023-3a04-4f8b-a8bf-339080f0dd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_device=device(type='mycelya', index=0)\n",
      "model_device=device(type='mycelya', index=1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{data_device=}\")\n",
    "print(f\"{model_device=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce3d397-47e6-44c0-9216-698d124782e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downscaled image:\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242,  1.5868, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.1187, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242,  1.7141,  1.3959, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242,  2.0960, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242,  1.7905, -0.0678, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]],\n",
      "       device='mycelya:0')\n",
      "Label: tensor(6, device='mycelya:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Downscaled image:\")\n",
    "print(train_data[0][0][0,0,::4,::4])\n",
    "print(\"Label:\", train_data[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8111c6fe-9156-487f-b51b-c541d6ec8ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on remote T4...\n",
      "Epoch 1/5 | train_loss: 0.4710 | test_acc: 95.34% | duration: 9.39s\n",
      "Epoch 2/5 | train_loss: 0.1310 | test_acc: 97.42% | duration: 7.59s\n",
      "Epoch 3/5 | train_loss: 0.0873 | test_acc: 98.00% | duration: 7.16s\n",
      "Epoch 4/5 | train_loss: 0.0682 | test_acc: 98.28% | duration: 7.40s\n",
      "Epoch 5/5 | train_loss: 0.0574 | test_acc: 98.46% | duration: 7.46s\n",
      "Took 39.00 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training on remote T4...\")\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_data, optimizer, criterion, model_device)\n",
    "    test_accuracy = evaluate(model, test_data, model_device)\n",
    "    duration = time.time() - epoch_start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{num_epochs} | \"\n",
    "        f\"train_loss: {train_loss:.4f} | \"\n",
    "        f\"test_acc: {test_accuracy * 100:.2f}% | \"\n",
    "        f\"duration: {duration:.2f}s\"\n",
    "    )\n",
    "duration = time.time() - start_time\n",
    "print(f\"Took {duration:.2f} seconds\")\n",
    "\n",
    "machine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635aa3fd-d361-45d3-9e97-ffa9ae62a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | train_loss: 0.5148 | test_acc: 94.68% | duration: 15.01s\n",
      "Epoch 2/5 | train_loss: 0.1443 | test_acc: 96.96% | duration: 15.07s\n",
      "Epoch 3/5 | train_loss: 0.0942 | test_acc: 97.71% | duration: 15.09s\n",
      "Epoch 4/5 | train_loss: 0.0723 | test_acc: 98.21% | duration: 15.12s\n",
      "Epoch 5/5 | train_loss: 0.0602 | test_acc: 98.44% | duration: 15.15s\n",
      "Took 75.44 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now compare with training on local CPU\n",
    "\n",
    "data_device = torch.device(\"cpu\")\n",
    "model_device = torch.device(\"cpu\")\n",
    "\n",
    "train_data = [(images.to(data_device), labels.to(data_device)) for images, labels in train_loader]\n",
    "test_data = [(images.to(data_device), labels.to(data_device)) for images, labels in test_loader]\n",
    "\n",
    "model = SimpleCNN().to(model_device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = 5\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_data, optimizer, criterion, model_device)\n",
    "    test_accuracy = evaluate(model, test_data, model_device)\n",
    "    duration = time.time() - epoch_start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{num_epochs} | \"\n",
    "        f\"train_loss: {train_loss:.4f} | \"\n",
    "        f\"test_acc: {test_accuracy * 100:.2f}% | \"\n",
    "        f\"duration: {duration:.2f}s\"\n",
    "    )\n",
    "duration = time.time() - start_time\n",
    "print(f\"Took {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d23aa2-e6e8-46f8-b217-eed7c5a22e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
